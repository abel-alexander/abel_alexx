import pandas as pd
import csv
import time

# Initialize the CSV file with headers before the loop
output_file = 'responses_with_details.csv'
with open(output_file, mode='w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    # Write header row
    writer.writerow([
        'Question', 
        'Llama_v1_Response', 
        'Llama_v2_Response', 
        'Mistral_Response', 
        'Inference_Time_Llama_v1 (s)', 
        'Inference_Time_Llama_v2 (s)', 
        'Inference_Time_Mistral (s)', 
        'Token_Length_Llama_v1', 
        'Token_Length_Llama_v2', 
        'Token_Length_Mistral'
    ])

# Process questions and save directly in the loop
for file in files:
    q = qa.get_q(i)  # Dynamically get question
    while q:  # Process each question
        # Timing and inference for llama_v1
        start_time = time.process_time()
        col_llama = llama1_qa(file_name, q)  # Call Llama v1 inference
        end_time = time.process_time()
        time_llama_v1 = end_time - start_time
        token_length_llama_v1 = len(col_llama.split())

        # Timing and inference for llama_v2
        start_time = time.process_time()
        col_llama2 = llama2_qa(file_name, q)  # Call Llama v2 inference
        end_time = time.process_time()
        time_llama_v2 = end_time - start_time
        token_length_llama_v2 = len(col_llama2.split())

        # Timing and inference for mistral
        start_time = time.process_time()
        col_mistral = mistral_qa(file_name, q)  # Call Mistral inference
        end_time = time.process_time()
        time_mistral = end_time - start_time
        token_length_mistral = len(col_mistral.split())

        # Write data directly to CSV
        with open(output_file, mode='a', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow([
                q, 
                col_llama, 
                col_llama2, 
                col_mistral, 
                time_llama_v1, 
                time_llama_v2, 
                time_mistral, 
                token_length_llama_v1, 
                token_length_llama_v2, 
                token_length_mistral
            ])

        # Get the next question
        q = qa.get_q(i)
